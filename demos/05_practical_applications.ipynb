{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e34337",
   "metadata": {},
   "source": [
    "# Practical Seismology Applications\n",
    "\n",
    "This notebook demonstrates practical applications of the `seisray` package for common seismological problems and research scenarios.\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply seisray to realistic seismological problems\n",
    "- Earthquake location and magnitude estimation\n",
    "- Regional velocity structure studies\n",
    "- Station array design and optimization\n",
    "- Quality control for seismic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add the parent directory to the path to import seisray\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from seisray import (TravelTimeCalculator, RayPathTracer, EarthPlotter,\n",
    "                     EarthModelManager, CoordinateConverter)\n",
    "\n",
    "print(\"Successfully imported seisray package!\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177e8ef",
   "metadata": {},
   "source": [
    "## 1. Earthquake Location Problem\n",
    "\n",
    "Let's simulate an earthquake location scenario using travel time differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d28770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a synthetic earthquake and station network\n",
    "# Earthquake location (unknown - to be determined)\n",
    "true_eq_lat = 37.5  # degrees N\n",
    "true_eq_lon = -122.0  # degrees W (San Francisco Bay Area)\n",
    "true_eq_depth = 8.0  # km\n",
    "true_origin_time = datetime(2024, 9, 5, 14, 30, 15)  # Origin time\n",
    "\n",
    "# Station network (known locations)\n",
    "stations = {\n",
    "    'STA1': {'lat': 37.8, 'lon': -122.4, 'name': 'Station 1'},\n",
    "    'STA2': {'lat': 37.2, 'lon': -121.8, 'name': 'Station 2'},\n",
    "    'STA3': {'lat': 37.6, 'lon': -121.5, 'name': 'Station 3'},\n",
    "    'STA4': {'lat': 37.9, 'lon': -121.9, 'name': 'Station 4'},\n",
    "    'STA5': {'lat': 37.1, 'lon': -122.2, 'name': 'Station 5'},\n",
    "}\n",
    "\n",
    "print(f\"Synthetic Earthquake Scenario:\")\n",
    "print(f\"  True location: {true_eq_lat:.2f}°N, {abs(true_eq_lon):.2f}°W\")\n",
    "print(f\"  True depth: {true_eq_depth:.1f} km\")\n",
    "print(f\"  Origin time: {true_origin_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nStation Network:\")\n",
    "for sta_code, sta_info in stations.items():\n",
    "    print(f\"  {sta_code}: {sta_info['lat']:.1f}°N, {abs(sta_info['lon']):.1f}°W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c95975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate true distances and generate synthetic arrival times\n",
    "calc = TravelTimeCalculator('iasp91')\n",
    "converter = CoordinateConverter()\n",
    "\n",
    "synthetic_arrivals = {}\n",
    "\n",
    "print(f\"\\nSynthetic Arrival Times:\")\n",
    "print(f\"{'Station':<8} {'Distance (km)':<12} {'Distance (°)':<12} {'P-time (s)':<12} {'S-time (s)':<12} {'S-P (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for sta_code, sta_info in stations.items():\n",
    "    # Calculate distance\n",
    "    dist_km, dist_deg, azimuth = converter.geographic_to_distance(\n",
    "        true_eq_lat, true_eq_lon, sta_info['lat'], sta_info['lon']\n",
    "    )\n",
    "\n",
    "    # Calculate travel times\n",
    "    arrivals = calc.calculate_travel_times(true_eq_depth, dist_deg)\n",
    "\n",
    "    # Find P and S arrivals\n",
    "    p_time = None\n",
    "    s_time = None\n",
    "\n",
    "    for arrival in arrivals:\n",
    "        if arrival.name == 'P' and p_time is None:\n",
    "            p_time = arrival.time\n",
    "        elif arrival.name == 'S' and s_time is None:\n",
    "            s_time = arrival.time\n",
    "\n",
    "    # Add some realistic noise (±0.1 seconds)\n",
    "    noise_p = np.random.normal(0, 0.1)\n",
    "    noise_s = np.random.normal(0, 0.15)\n",
    "\n",
    "    p_time_noisy = p_time + noise_p\n",
    "    s_time_noisy = s_time + noise_s\n",
    "    sp_time = s_time_noisy - p_time_noisy\n",
    "\n",
    "    # Calculate absolute arrival times\n",
    "    p_arrival_time = true_origin_time + timedelta(seconds=p_time_noisy)\n",
    "    s_arrival_time = true_origin_time + timedelta(seconds=s_time_noisy)\n",
    "\n",
    "    synthetic_arrivals[sta_code] = {\n",
    "        'distance_km': dist_km,\n",
    "        'distance_deg': dist_deg,\n",
    "        'azimuth': azimuth,\n",
    "        'p_time': p_time_noisy,\n",
    "        's_time': s_time_noisy,\n",
    "        'sp_time': sp_time,\n",
    "        'p_arrival': p_arrival_time,\n",
    "        's_arrival': s_arrival_time\n",
    "    }\n",
    "\n",
    "    print(f\"{sta_code:<8} {dist_km:<12.1f} {dist_deg:<12.2f} {p_time_noisy:<12.2f} {s_time_noisy:<12.2f} {sp_time:<10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the earthquake-station geometry\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Plot stations\n",
    "for sta_code, sta_info in stations.items():\n",
    "    ax.plot(sta_info['lon'], sta_info['lat'], 'g^', markersize=12, label='Stations' if sta_code == 'STA1' else '')\n",
    "    ax.annotate(sta_code, (sta_info['lon'], sta_info['lat']),\n",
    "               xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "# Plot true earthquake location\n",
    "ax.plot(true_eq_lon, true_eq_lat, 'r*', markersize=20, label='True Earthquake')\n",
    "\n",
    "# Plot distance circles\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange']\n",
    "for i, (sta_code, sta_info) in enumerate(stations.items()):\n",
    "    arrival_data = synthetic_arrivals[sta_code]\n",
    "\n",
    "    # Convert distance to approximate degrees for plotting\n",
    "    dist_deg_approx = arrival_data['distance_km'] / 111.0  # Rough conversion\n",
    "\n",
    "    circle = Circle((sta_info['lon'], sta_info['lat']), dist_deg_approx,\n",
    "                   fill=False, color=colors[i], linewidth=2, alpha=0.7,\n",
    "                   label=f'{sta_code} ({arrival_data[\"distance_km\"]:.1f} km)')\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "ax.set_xlabel('Longitude (degrees)')\n",
    "ax.set_ylabel('Latitude (degrees)')\n",
    "ax.set_title('Earthquake Location Problem\\nTrue location and station distances')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f89cf0",
   "metadata": {},
   "source": [
    "## 2. Regional Velocity Structure Study\n",
    "\n",
    "Let's compare how different Earth models perform for this regional study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389004ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different Earth models for regional distances\n",
    "models = ['iasp91', 'prem', 'ak135']\n",
    "regional_distances = np.array([10, 20, 30, 40, 50])  # degrees - regional scale\n",
    "regional_depth = 15  # km - typical crustal earthquake\n",
    "\n",
    "model_comparison = {}\n",
    "\n",
    "print(f\"Regional Velocity Structure Comparison:\")\n",
    "print(f\"Source depth: {regional_depth} km\")\n",
    "print(f\"\\nP-wave Travel Times (seconds):\")\n",
    "print(f\"{'Distance (°)':<12}\", end=\"\")\n",
    "for model in models:\n",
    "    print(f\"{model.upper():<10}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * (12 + 10 * len(models)))\n",
    "\n",
    "for distance in regional_distances:\n",
    "    print(f\"{distance:<12.0f}\", end=\"\")\n",
    "\n",
    "    distance_data = {}\n",
    "    for model in models:\n",
    "        calc = TravelTimeCalculator(model)\n",
    "        arrivals = calc.calculate_travel_times(regional_depth, distance)\n",
    "\n",
    "        # Find P arrival\n",
    "        p_time = None\n",
    "        for arrival in arrivals:\n",
    "            if arrival.name == 'P':\n",
    "                p_time = arrival.time\n",
    "                break\n",
    "\n",
    "        distance_data[model] = p_time\n",
    "        print(f\"{p_time:<10.2f}\", end=\"\")\n",
    "\n",
    "    model_comparison[distance] = distance_data\n",
    "    print()\n",
    "\n",
    "# Calculate residuals relative to IASP91\n",
    "print(f\"\\nResiduals relative to IASP91 (seconds):\")\n",
    "print(f\"{'Distance (°)':<12}\", end=\"\")\n",
    "for model in models[1:]:  # Skip IASP91\n",
    "    print(f\"{model.upper()}-IASP91:<15}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * (12 + 15 * (len(models) - 1)))\n",
    "\n",
    "for distance in regional_distances:\n",
    "    print(f\"{distance:<12.0f}\", end=\"\")\n",
    "\n",
    "    iasp91_time = model_comparison[distance]['iasp91']\n",
    "    for model in models[1:]:\n",
    "        residual = model_comparison[distance][model] - iasp91_time\n",
    "        print(f\"{residual:<15.3f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regional travel time curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "# Travel time curves\n",
    "ax = axes[0]\n",
    "for model, color in zip(models, colors):\n",
    "    times = [model_comparison[dist][model] for dist in regional_distances]\n",
    "    ax.plot(regional_distances, times, color=color, linewidth=2,\n",
    "           marker='o', markersize=6, label=model.upper())\n",
    "\n",
    "ax.set_xlabel('Distance (degrees)')\n",
    "ax.set_ylabel('P-wave Travel Time (s)')\n",
    "ax.set_title(f'Regional P-wave Travel Times\\n(Depth = {regional_depth} km)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "ax = axes[1]\n",
    "for model, color in zip(models[1:], colors[1:]):\n",
    "    residuals = [model_comparison[dist][model] - model_comparison[dist]['iasp91']\n",
    "                for dist in regional_distances]\n",
    "    ax.plot(regional_distances, residuals, color=color, linewidth=2,\n",
    "           marker='s', markersize=6, label=f'{model.upper()} - IASP91')\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Distance (degrees)')\n",
    "ax.set_ylabel('Travel Time Residual (s)')\n",
    "ax.set_title('Model Residuals (relative to IASP91)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\nStatistical Summary of Model Differences:\")\n",
    "for model in models[1:]:\n",
    "    residuals = [model_comparison[dist][model] - model_comparison[dist]['iasp91']\n",
    "                for dist in regional_distances]\n",
    "    print(f\"{model.upper()} vs IASP91:\")\n",
    "    print(f\"  Mean residual: {np.mean(residuals):.3f} s\")\n",
    "    print(f\"  RMS residual: {np.sqrt(np.mean(np.array(residuals)**2)):.3f} s\")\n",
    "    print(f\"  Max absolute: {np.max(np.abs(residuals)):.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae1ad5",
   "metadata": {},
   "source": [
    "## 3. Station Array Design\n",
    "\n",
    "Let's design an optimal station array for monitoring local seismicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a circular station array\n",
    "center_lat = 37.5  # degrees N\n",
    "center_lon = -122.0  # degrees W\n",
    "array_radius = 50  # km\n",
    "n_stations = 8\n",
    "\n",
    "# Create station array\n",
    "converter = CoordinateConverter()\n",
    "array_stations = converter.create_station_array(center_lat, center_lon,\n",
    "                                               array_radius, n_stations)\n",
    "\n",
    "print(f\"Optimal Station Array Design:\")\n",
    "print(f\"  Center: {center_lat:.2f}°N, {abs(center_lon):.2f}°W\")\n",
    "print(f\"  Radius: {array_radius} km\")\n",
    "print(f\"  Number of stations: {n_stations}\")\n",
    "print(f\"\\nStation Coordinates:\")\n",
    "print(f\"{'Station':<8} {'Latitude':<10} {'Longitude':<11} {'Distance (km)':<13} {'Azimuth (°)':<12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "array_info = []\n",
    "for i, (lat, lon) in enumerate(array_stations):\n",
    "    dist_km, dist_deg, azimuth = converter.geographic_to_distance(\n",
    "        center_lat, center_lon, lat, lon\n",
    "    )\n",
    "\n",
    "    station_name = f\"ARR{i+1:02d}\"\n",
    "    array_info.append({\n",
    "        'name': station_name,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'distance': dist_km,\n",
    "        'azimuth': azimuth\n",
    "    })\n",
    "\n",
    "    print(f\"{station_name:<8} {lat:<10.3f} {lon:<11.3f} {dist_km:<13.1f} {azimuth:<12.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze array performance for different earthquake scenarios\n",
    "test_earthquakes = [\n",
    "    {'lat': 37.5, 'lon': -122.0, 'depth': 5, 'name': 'Central'},\n",
    "    {'lat': 37.6, 'lon': -121.9, 'depth': 10, 'name': 'Northeast'},\n",
    "    {'lat': 37.4, 'lon': -122.1, 'depth': 15, 'name': 'Southwest'},\n",
    "    {'lat': 37.5, 'lon': -121.8, 'depth': 8, 'name': 'East'},\n",
    "]\n",
    "\n",
    "print(f\"\\nArray Performance Analysis:\")\n",
    "print(f\"Testing {len(test_earthquakes)} earthquake scenarios...\\n\")\n",
    "\n",
    "calc = TravelTimeCalculator('iasp91')\n",
    "array_performance = {}\n",
    "\n",
    "for eq in test_earthquakes:\n",
    "    print(f\"Earthquake: {eq['name']} ({eq['lat']:.2f}°N, {abs(eq['lon']):.2f}°W, {eq['depth']} km)\")\n",
    "    print(f\"{'Station':<8} {'Distance (km)':<12} {'P-time (s)':<12} {'S-time (s)':<12} {'S-P (s)':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    eq_data = []\n",
    "\n",
    "    for station in array_info:\n",
    "        # Calculate distance to earthquake\n",
    "        dist_km, dist_deg, azimuth = converter.geographic_to_distance(\n",
    "            eq['lat'], eq['lon'], station['lat'], station['lon']\n",
    "        )\n",
    "\n",
    "        # Calculate travel times\n",
    "        arrivals = calc.calculate_travel_times(eq['depth'], dist_deg)\n",
    "\n",
    "        # Find P and S arrivals\n",
    "        p_time = None\n",
    "        s_time = None\n",
    "\n",
    "        for arrival in arrivals:\n",
    "            if arrival.name == 'P' and p_time is None:\n",
    "                p_time = arrival.time\n",
    "            elif arrival.name == 'S' and s_time is None:\n",
    "                s_time = arrival.time\n",
    "\n",
    "        sp_time = s_time - p_time if (s_time and p_time) else None\n",
    "\n",
    "        eq_data.append({\n",
    "            'station': station['name'],\n",
    "            'distance': dist_km,\n",
    "            'p_time': p_time,\n",
    "            's_time': s_time,\n",
    "            'sp_time': sp_time\n",
    "        })\n",
    "\n",
    "        print(f\"{station['name']:<8} {dist_km:<12.1f} {p_time:<12.2f} {s_time:<12.2f} {sp_time:<10.2f}\")\n",
    "\n",
    "    # Calculate array statistics\n",
    "    distances = [d['distance'] for d in eq_data]\n",
    "    p_times = [d['p_time'] for d in eq_data]\n",
    "\n",
    "    print(f\"\\nArray Statistics:\")\n",
    "    print(f\"  Distance range: {np.min(distances):.1f} - {np.max(distances):.1f} km\")\n",
    "    print(f\"  P-time range: {np.min(p_times):.2f} - {np.max(p_times):.2f} s\")\n",
    "    print(f\"  P-time spread: {np.max(p_times) - np.min(p_times):.2f} s\")\n",
    "    print(f\"  Azimuthal coverage: Good (circular array)\\n\")\n",
    "\n",
    "    array_performance[eq['name']] = eq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f68b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize array design and performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Array geometry\n",
    "ax = axes[0, 0]\n",
    "# Plot array stations\n",
    "for station in array_info:\n",
    "    ax.plot(station['lon'], station['lat'], 'g^', markersize=10)\n",
    "    ax.annotate(station['name'], (station['lon'], station['lat']),\n",
    "               xytext=(3, 3), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Plot test earthquakes\n",
    "colors_eq = ['red', 'blue', 'green', 'purple']\n",
    "for eq, color in zip(test_earthquakes, colors_eq):\n",
    "    ax.plot(eq['lon'], eq['lat'], 'o', color=color, markersize=8, label=eq['name'])\n",
    "\n",
    "# Plot array circle\n",
    "array_circle = Circle((center_lon, center_lat), array_radius/111.0,\n",
    "                     fill=False, color='gray', linestyle='--', alpha=0.7)\n",
    "ax.add_patch(array_circle)\n",
    "\n",
    "ax.set_xlabel('Longitude (degrees)')\n",
    "ax.set_ylabel('Latitude (degrees)')\n",
    "ax.set_title('Station Array Design')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Travel time analysis for each earthquake\n",
    "for i, (eq, color) in enumerate(zip(test_earthquakes, colors_eq)):\n",
    "    if i < 3:  # Plot first 3 earthquakes\n",
    "        row = (i + 1) // 2\n",
    "        col = (i + 1) % 2\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        eq_data = array_performance[eq['name']]\n",
    "        stations_names = [d['station'] for d in eq_data]\n",
    "        p_times = [d['p_time'] for d in eq_data]\n",
    "        s_times = [d['s_time'] for d in eq_data]\n",
    "\n",
    "        x_pos = np.arange(len(stations_names))\n",
    "\n",
    "        ax.bar(x_pos - 0.2, p_times, 0.4, label='P-wave', color='blue', alpha=0.7)\n",
    "        ax.bar(x_pos + 0.2, s_times, 0.4, label='S-wave', color='red', alpha=0.7)\n",
    "\n",
    "        ax.set_xlabel('Station')\n",
    "        ax.set_ylabel('Travel Time (s)')\n",
    "        ax.set_title(f'Travel Times: {eq[\"name\"]} Earthquake')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(stations_names, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca99aa",
   "metadata": {},
   "source": [
    "## 4. Quality Control and Data Validation\n",
    "\n",
    "Let's demonstrate how to use seisray for quality control of seismic arrival times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate realistic arrival time data with some outliers\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "# Reference earthquake\n",
    "ref_eq_lat = 37.5\n",
    "ref_eq_lon = -122.0\n",
    "ref_eq_depth = 12\n",
    "\n",
    "# Simulate observations from a regional network\n",
    "observed_data = []\n",
    "station_coords = [\n",
    "    {'name': 'STA01', 'lat': 37.8, 'lon': -122.3, 'quality': 'good'},\n",
    "    {'name': 'STA02', 'lat': 37.2, 'lon': -121.7, 'quality': 'good'},\n",
    "    {'name': 'STA03', 'lat': 37.6, 'lon': -121.5, 'quality': 'good'},\n",
    "    {'name': 'STA04', 'lat': 37.9, 'lon': -122.1, 'quality': 'noisy'},  # Noisy station\n",
    "    {'name': 'STA05', 'lat': 37.1, 'lon': -122.4, 'quality': 'good'},\n",
    "    {'name': 'STA06', 'lat': 37.7, 'lon': -121.8, 'quality': 'outlier'},  # Bad pick\n",
    "]\n",
    "\n",
    "calc = TravelTimeCalculator('iasp91')\n",
    "converter = CoordinateConverter()\n",
    "\n",
    "print(f\"Quality Control Analysis:\")\n",
    "print(f\"Reference earthquake: {ref_eq_lat:.2f}°N, {abs(ref_eq_lon):.2f}°W, {ref_eq_depth} km\")\n",
    "print(f\"\\n{'Station':<8} {'Dist(km)':<8} {'Predicted':<10} {'Observed':<10} {'Residual':<10} {'Quality':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for station in station_coords:\n",
    "    # Calculate true distance and predicted travel time\n",
    "    dist_km, dist_deg, azimuth = converter.geographic_to_distance(\n",
    "        ref_eq_lat, ref_eq_lon, station['lat'], station['lon']\n",
    "    )\n",
    "\n",
    "    arrivals = calc.calculate_travel_times(ref_eq_depth, dist_deg)\n",
    "    predicted_p = None\n",
    "    for arrival in arrivals:\n",
    "        if arrival.name == 'P':\n",
    "            predicted_p = arrival.time\n",
    "            break\n",
    "\n",
    "    # Simulate observed time with appropriate noise/errors\n",
    "    if station['quality'] == 'good':\n",
    "        noise = np.random.normal(0, 0.1)  # ±0.1 s standard error\n",
    "    elif station['quality'] == 'noisy':\n",
    "        noise = np.random.normal(0, 0.3)  # ±0.3 s standard error\n",
    "    elif station['quality'] == 'outlier':\n",
    "        noise = np.random.normal(2.0, 0.2)  # Systematic +2s error (bad pick)\n",
    "\n",
    "    observed_p = predicted_p + noise\n",
    "    residual = observed_p - predicted_p\n",
    "\n",
    "    observed_data.append({\n",
    "        'station': station['name'],\n",
    "        'distance': dist_km,\n",
    "        'predicted': predicted_p,\n",
    "        'observed': observed_p,\n",
    "        'residual': residual,\n",
    "        'quality': station['quality']\n",
    "    })\n",
    "\n",
    "    print(f\"{station['name']:<8} {dist_km:<8.1f} {predicted_p:<10.2f} {observed_p:<10.2f} {residual:<10.2f} {station['quality']:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality control analysis\n",
    "residuals = np.array([d['residual'] for d in observed_data])\n",
    "distances = np.array([d['distance'] for d in observed_data])\n",
    "stations = [d['station'] for d in observed_data]\n",
    "\n",
    "# Statistical analysis\n",
    "mean_residual = np.mean(residuals)\n",
    "std_residual = np.std(residuals)\n",
    "rms_residual = np.sqrt(np.mean(residuals**2))\n",
    "\n",
    "print(f\"\\nQuality Control Statistics:\")\n",
    "print(f\"  Mean residual: {mean_residual:.3f} s\")\n",
    "print(f\"  Standard deviation: {std_residual:.3f} s\")\n",
    "print(f\"  RMS residual: {rms_residual:.3f} s\")\n",
    "\n",
    "# Outlier detection (3-sigma rule)\n",
    "outlier_threshold = 3 * std_residual\n",
    "outliers = np.abs(residuals) > outlier_threshold\n",
    "\n",
    "print(f\"\\nOutlier Detection (3σ rule):\")\n",
    "print(f\"  Threshold: ±{outlier_threshold:.3f} s\")\n",
    "print(f\"  Outliers detected: {np.sum(outliers)} stations\")\n",
    "\n",
    "if np.any(outliers):\n",
    "    print(f\"  Outlier stations:\")\n",
    "    for i, is_outlier in enumerate(outliers):\n",
    "        if is_outlier:\n",
    "            print(f\"    {stations[i]}: {residuals[i]:.3f} s\")\n",
    "\n",
    "# Alternative robust statistics (median-based)\n",
    "median_residual = np.median(residuals)\n",
    "mad_residual = np.median(np.abs(residuals - median_residual))  # Median Absolute Deviation\n",
    "robust_outliers = np.abs(residuals - median_residual) > 3 * mad_residual\n",
    "\n",
    "print(f\"\\nRobust Outlier Detection (Median + MAD):\")\n",
    "print(f\"  Median residual: {median_residual:.3f} s\")\n",
    "print(f\"  MAD: {mad_residual:.3f} s\")\n",
    "print(f\"  Robust outliers: {np.sum(robust_outliers)} stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89731abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize quality control results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Residuals vs distance\n",
    "ax = axes[0, 0]\n",
    "colors = ['green' if q == 'good' else 'orange' if q == 'noisy' else 'red'\n",
    "          for q in [d['quality'] for d in observed_data]]\n",
    "scatter = ax.scatter(distances, residuals, c=colors, s=80, alpha=0.7)\n",
    "ax.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "ax.axhline(outlier_threshold, color='red', linestyle='--', alpha=0.7, label=f'3σ = ±{outlier_threshold:.2f}s')\n",
    "ax.axhline(-outlier_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Distance (km)')\n",
    "ax.set_ylabel('Travel Time Residual (s)')\n",
    "ax.set_title('Residuals vs Distance')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual histogram\n",
    "ax = axes[0, 1]\n",
    "ax.hist(residuals, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax.axvline(mean_residual, color='red', linestyle='-', linewidth=2, label=f'Mean = {mean_residual:.3f}s')\n",
    "ax.axvline(median_residual, color='green', linestyle='-', linewidth=2, label=f'Median = {median_residual:.3f}s')\n",
    "ax.axvline(outlier_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "ax.axvline(-outlier_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Travel Time Residual (s)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Residual Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Travel time curves\n",
    "ax = axes[1, 0]\n",
    "predicted_times = [d['predicted'] for d in observed_data]\n",
    "observed_times = [d['observed'] for d in observed_data]\n",
    "\n",
    "ax.scatter(distances, predicted_times, color='blue', s=60, label='Predicted', alpha=0.7)\n",
    "ax.scatter(distances, observed_times, c=colors, s=60, label='Observed', alpha=0.7)\n",
    "\n",
    "# Connect predicted and observed for each station\n",
    "for i in range(len(distances)):\n",
    "    ax.plot([distances[i], distances[i]], [predicted_times[i], observed_times[i]],\n",
    "           'k-', alpha=0.3, linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Distance (km)')\n",
    "ax.set_ylabel('Travel Time (s)')\n",
    "ax.set_title('Predicted vs Observed Travel Times')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Station quality summary\n",
    "ax = axes[1, 1]\n",
    "station_names = [d['station'] for d in observed_data]\n",
    "station_residuals = [d['residual'] for d in observed_data]\n",
    "station_colors = ['green' if abs(r) <= outlier_threshold else 'red' for r in station_residuals]\n",
    "\n",
    "bars = ax.bar(range(len(station_names)), station_residuals, color=station_colors, alpha=0.7)\n",
    "ax.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "ax.axhline(outlier_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "ax.axhline(-outlier_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Station')\n",
    "ax.set_ylabel('Travel Time Residual (s)')\n",
    "ax.set_title('Station Quality Assessment')\n",
    "ax.set_xticks(range(len(station_names)))\n",
    "ax.set_xticklabels(station_names, rotation=45)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quality summary\n",
    "good_stations = [d['station'] for d in observed_data if abs(d['residual']) <= outlier_threshold]\n",
    "bad_stations = [d['station'] for d in observed_data if abs(d['residual']) > outlier_threshold]\n",
    "\n",
    "print(f\"\\nFinal Quality Assessment:\")\n",
    "print(f\"  Good stations ({len(good_stations)}): {', '.join(good_stations)}\")\n",
    "print(f\"  Problematic stations ({len(bad_stations)}): {', '.join(bad_stations)}\")\n",
    "print(f\"  Overall data quality: {len(good_stations)}/{len(observed_data)} stations passed QC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ffd8a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated practical applications of the `seisray` package:\n",
    "\n",
    "1. **Earthquake Location**: \n",
    "   - Simulated realistic source-receiver geometries\n",
    "   - Generated synthetic arrival times with noise\n",
    "   - Analyzed station network coverage\n",
    "\n",
    "2. **Regional Velocity Structure Studies**:\n",
    "   - Compared different Earth models for regional distances\n",
    "   - Quantified model differences and uncertainties\n",
    "   - Assessed model performance for specific regions\n",
    "\n",
    "3. **Station Array Design**:\n",
    "   - Designed optimal circular station arrays\n",
    "   - Analyzed array performance for different earthquake scenarios\n",
    "   - Evaluated azimuthal coverage and timing resolution\n",
    "\n",
    "4. **Quality Control and Data Validation**:\n",
    "   - Implemented statistical outlier detection methods\n",
    "   - Compared predicted vs observed travel times\n",
    "   - Assessed data quality and station performance\n",
    "\n",
    "### Key Practical Insights:\n",
    "\n",
    "**Earthquake Location:**\n",
    "- Good azimuthal coverage is essential for accurate locations\n",
    "- S-P times provide additional constraints for depth estimation\n",
    "- Regional networks typically achieve ~1-5 km location accuracy\n",
    "\n",
    "**Model Selection:**\n",
    "- Model differences are typically <1 second for regional distances\n",
    "- IASP91 remains adequate for most regional studies\n",
    "- Local velocity models may be needed for high-precision work\n",
    "\n",
    "**Array Design:**\n",
    "- Circular arrays provide optimal azimuthal coverage\n",
    "- Array aperture should match expected source distances\n",
    "- 6-12 stations often provide good balance of cost vs. performance\n",
    "\n",
    "**Quality Control:**\n",
    "- Outlier detection is crucial for reliable analysis\n",
    "- 3σ rule catches most obvious errors\n",
    "- Robust statistics help with non-Gaussian error distributions\n",
    "- Systematic station biases may indicate calibration issues\n",
    "\n",
    "### Applications in Research:\n",
    "- **Seismic monitoring networks**: Design and optimization\n",
    "- **Regional tomography**: Data quality assessment\n",
    "- **Earthquake early warning**: Network performance analysis\n",
    "- **Induced seismicity studies**: Local network design\n",
    "- **Educational purposes**: Understanding seismic wave propagation\n",
    "\n",
    "The `seisray` package provides essential tools for practical seismological applications, from research planning to data analysis and quality control."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
